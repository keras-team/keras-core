"""
scatter
scatter_update
slice
slice_update
while_loop
stop_gradient
shape
cast
convert_to_tensor
convert_to_numpy
"""

import numpy as np

from keras_core import backend
from keras_core.api_export import keras_core_export
from keras_core.backend import KerasTensor
from keras_core.backend import any_symbolic_tensors
from keras_core.ops.operation import Operation


class Scatter(Operation):
    def call(self, indices, values, shape):
        return backend.core.scatter(indices, values, shape)

    def compute_output_spec(self, indices, values, shape):
        return KerasTensor(shape, dtype=values.dtype)


@keras_core_export("keras_core.ops.scatter")
def scatter(indices, values, shape):
    if any_symbolic_tensors((indices, values, shape)):
        return Scatter().symbolic_call(indices, values, shape)
    return backend.core.scatter(indices, values, shape)


class ScatterUpdate(Operation):
    def call(self, inputs, indices, updates):
        return backend.core.scatter_update(inputs, indices, updates)

    def compute_output_spec(self, inputs, indices, updates):
        return KerasTensor(inputs.shape, dtype=inputs.dtype)


@keras_core_export("keras_core.ops.scatter_update")
def scatter_update(inputs, indices, updates):
    """Update inputs via updates at scattered (sparse) indices.

    At a high level, this operation does `inputs[indices] = updates`.
    Assume `inputs` is a tensor of shape `(D0, D1, ..., Dn)`, there are 2 main
    usages of `scatter_update`.

    1. `indices` is a 2D tensor of shape `(num_updates, n)`, where `num_updates`
        is the number of updates to perform, and `updates` is a 1D tensor of
        shape `(num_updates,)`. For example, if `inputs` is `zeros((4, 4, 4))`,
        and we want to update `inputs[1, 2, 3]` and `inputs[0, 1, 3]` as 1, then
        we can use:

    ```python
    inputs = np.zeros((4, 4, 4))
    indices = [[1, 2, 3], [0, 1, 3]]
    updates = np.array([1., 1.])
    inputs = keras_core.ops.scatter_update(inputs, indices, updates)
    ```

    2 `indices` is a 2D tensor of shape `(num_updates, k)`, where `num_updates`
        is the number of updates to perform, and `k` (`k < n`) is the size of
        each index in `indices`. `updates` is a `n - k`-D tensor of shape
        `(num_updates, inputs.shape[k:])`. For example, if
        `inputs = np.zeros((4, 4, 4))`, and we want to update `inputs[1, 2, :]`
        and `inputs[2, 3, :]` as `[1, 1, 1, 1]`, then `indices` would have shape
        `(num_updates, 2)` (`k = 2`), and `updates` would have shape
        `(num_updates, 4)` (`inputs.shape[2:] = 4`). See the code below:

    ```python
    inputs = np.zeros((4, 4, 4))
    indices = [[1, 2], [2, 3]]
    updates = np.array([[1., 1., 1, 1,], [1., 1., 1, 1,])
    inputs = keras_core.ops.scatter_update(inputs, indices, updates)
    ```

    Args:
        inputs: A tensor, the tensor to be updated.
        indices: A tensor or list/tuple of shape `(N, inputs.ndim)`, specifying
            indices to update. `N` is the number of indices to update, must be
            equal to the first dimension of `updates`.
        updates: A tensor, the new values to be put to `inputs` at `indices`.

    Returns:
        A tensor, has the same shape and dtype as `inputs`.
    """
    if any_symbolic_tensors((inputs, indices, updates)):
        return ScatterUpdate().symbolic_call(inputs, indices, updates)
    return backend.core.scatter_update(inputs, indices, updates)


class Slice(Operation):
    def call(self, inputs, start_indices, shape):
        return backend.core.slice(inputs, start_indices, shape)

    def compute_output_spec(self, inputs, start_indices, shape):
        return KerasTensor(shape, dtype=inputs.dtype)


@keras_core_export("keras_core.ops.slice")
def slice(inputs, start_indices, shape):
    """Return a slice of an input tensor.

    At a high level, this operation is an explicit replacement for array slicing
    e.g. `inputs[start_indices: start_indices + shape]`.
    Unlike slicing via brackets, this operation will accept tensor start
    indices on all backends, which is useful when indices dynamically computed
    via other tensor operations.

    ```python
    inputs = np.zeros((5, 5))
    start_indices = np.array([3, 3])
    shape = np.array([2, 2])
    inputs = keras_core.ops.slice(inputs, start_indices, updates)
    ```

    Args:
        inputs: A tensor, the tensor to be updated.
        start_indices: A list/tuple of shape `(inputs.ndim,)`, specifying
            the starting indices for updating.
        shape: The full shape of the returned slice.

    Returns:
        A tensor, has the same shape and dtype as `inputs`.
    """
    if any_symbolic_tensors((inputs, start_indices, shape)):
        return Slice().symbolic_call(inputs, start_indices, shape)
    return backend.core.slice(inputs, start_indices, shape)


class SliceUpdate(Operation):
    def call(self, inputs, start_indices, updates):
        return backend.core.slice_update(inputs, start_indices, updates)

    def compute_output_spec(self, inputs, start_indices, updates):
        return KerasTensor(inputs.shape, dtype=inputs.dtype)


@keras_core_export("keras_core.ops.slice_update")
def slice_update(inputs, start_indices, updates):
    """Update an input by slicing in a tensor of updated values.

    At a high level, this operation does
    `inputs[start_indices: start_indices + updates.shape] = updates`.
    Assume inputs is a tensor of shape `(D0, D1, ..., Dn)`,
    `start_indices` must be a list/tuple of n integers, specifying the starting
    indices. `updates` must have the same rank as `inputs`, and the size of each
    dim must not exceed `Di - start_indices[i]`. For example, if we have 2D
    inputs `inputs = np.zeros((5, 5))`, and we want to update the intersection
    of last 2 rows and last 2 columns as 1, i.e.,
    `inputs[3:, 3:] = np.ones((2, 2))`, then we can use the code below:

    ```python
    inputs = np.zeros((5, 5))
    start_indices = [3, 3]
    updates = np.ones((2, 2))
    inputs = keras_core.ops.slice_update(inputs, start_indices, updates)
    ```

    Args:
        inputs: A tensor, the tensor to be updated.
        start_indices: A list/tuple of shape `(inputs.ndim,)`, specifying
            the starting indices for updating.
        updates: A tensor, the new values to be put to `inputs` at `indices`.
            `updates` must have the same rank as `inputs`.

    Returns:
        A tensor, has the same shape and dtype as `inputs`.
    """
    if any_symbolic_tensors((inputs, start_indices, updates)):
        return SliceUpdate().symbolic_call(inputs, start_indices, updates)
    return backend.core.slice_update(inputs, start_indices, updates)


class WhileLoop(Operation):
    def __init__(self, cond, body, maximum_iterations):
        super().__init__()
        self.cond = cond
        self.body = body
        self.maximum_iterations = maximum_iterations

    def call(self, loop_vars):
        return backend.core.while_loop(
            self.cond,
            self.body,
            loop_vars,
            maximum_iterations=self.maximum_iterations,
        )

    def compute_output_spec(self, loop_vars):
        return [KerasTensor(v.shape, dtype=v.dtype) for v in loop_vars]


@keras_core_export("keras_core.ops.while_loop")
def while_loop(
    cond,
    body,
    loop_vars,
    maximum_iterations=None,
):
    """While loop implemetation.

    Args:
        cond: A callable that represents the termination condition of the loop.
            Must have the same number of args as `loop_vars`, and return a bool.
        body: A callable that represents the loop body. Must have the same
            number of args as `loop_vars`, and return a list/tuple of the same
            length, shape and dtype as `loop_vars`.
        loop_vars: A list/tuple of tensors, the loop variables.
        maximum_iterations: Optional maximum number of iterations of the while
            loop to run. If provided, the `cond` output is AND-ed with an
            additional condition ensuring the number of iterations executed is
            no greater than `maximum_iterations`.

    Returns:
        A list/tuple of tensors, has the same shape and dtype as `inputs`.

    Examples:

    >>> i = 0
    >>> cond = lambda i: i < 10
    >>> body = lambda i: i + 1
    >>> keras_core.ops.while_loop(cond, body, [i])[0]
    10
    """

    return backend.core.while_loop(
        cond,
        body,
        loop_vars,
        maximum_iterations=maximum_iterations,
    )


class StopGradient(Operation):
    def __init__(self):
        super().__init__()

    def call(self, variable):
        return backend.core.stop_gradient(variable)

    def compute_output_spec(self, variable):
        return KerasTensor(variable.shape, dtype=variable.dtype)


@keras_core_export("keras_core.ops.stop_gradient")
def stop_gradient(variable):
    """Stops gradient computation.

    Args:
        variable: A tensor variable for which the gradient
            computation is to be disabled.

    Returns:
        The variable with gradient computation disabled.

    Examples:

    >>> var = keras_core.backend.convert_to_tensor(
    ...     [1., 2., 3.],
    ...     dtype="float32"
    ... )
    >>> var = keras_core.ops.stop_gradient(var)
    """
    return backend.core.stop_gradient(variable)


@keras_core_export("keras_core.ops.shape")
def shape(x):
    """
    Gets the shape of the tensor input.

    Args:
        x: A tensor. This function will try to access the `shape` attribute of
            the input tensor. When using TensorFlow backend the input can also
            be a list.

    Returns:
        A tuple of integers, the shape of the tensor.

    Examples:
        TensorFlow Backend with a list:
        >>> keras_core.ops.shape([812])
        >>> <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

        >>> keras_core.ops.shape([[1, 2, 3], [4, 5, 6]])
        >>> <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>

        PyTorch Tensor:
        >>> keras_core.ops.shape(torch.Tensor([[1, 2, 3], [4, 5, 6]]))
        >>> torch.Size([2, 3])

        TensorFlow Tensor:
        >>> keras_core.ops.shape(tf.constant([[1, 2, 3], [4, 5, 6]]))
        >>> <tf.Tensor: shape=(2,), dtype=int32,
        ...     numpy=array([2, 3], dtype=int32)>

    """

    if any_symbolic_tensors((x,)):
        return x.shape
    return backend.core.shape(x)


@keras_core_export("keras_core.ops.cast")
def cast(x, dtype):
    """
    Cast a tensor to the desired dtype.

    Args:
        x: A tensor or variable.
        dtype: The target type.

    Returns:
        A tensor of the specified `dtype`.

    Examples:
        TensorFlow Backend:
            >>> keras_core.ops.cast([1, 2, 3], "float32")
            >>> <tf.Tensor: shape=(3,), dtype=float32,
            ...     numpy=array([1., 2., 3.], dtype=float32)>

        PyTorch Backend:
            >>> keras_core.ops.cast([1, 2, 3], "float32")
            >>> tensor([1., 2., 3.])

        JAX Backend:
            >>> keras_core.ops.cast([1, 2, 3], "float32")
            >>> Array([1., 2., 3.], dtype=float32)

    """
    dtype = backend.standardize_dtype(dtype)

    if any_symbolic_tensors((x,)):
        return backend.KerasTensor(shape=x.shape, dtype=dtype)
    return backend.core.cast(x, dtype)


@keras_core_export("keras_core.ops.convert_to_tensor")
def convert_to_tensor(x, dtype=None):
    """
    Convert a NumPy array to a tensor.
    
    Args:
        x: A NumPy array or a tensor.
        dtype: The target type.
        
    Returns:
        A tensor of the specified `dtype`.
        
    Examples:
        TensorFlow Backend:
            >>> keras_core.ops.convert_to_tensor(np.array([1, 2, 3]), "float32")
            >>> <tf.Tensor: shape=(3,), dtype=float32,
            ...     numpy=array([1., 2., 3.], dtype=float32)>
            
        PyTorch Backend:
            >>> keras_core.ops.convert_to_tensor(np.array([1, 2, 3]), "float32")
            >>> tensor([1., 2., 3.])
            
        JAX Backend:
            >>> keras_core.ops.convert_to_tensor(np.array([1, 2, 3]), "float32")
            >>> Array([1., 2., 3.], dtype=float32)
    """

    return backend.convert_to_tensor(x, dtype=dtype)


@keras_core_export("keras_core.ops.convert_to_numpy")
def convert_to_numpy(x):
    """
    Convert a tensor to a NumPy array.

    Args:
        x: A tensor.

    Returns:
        A NumPy array.

    Examples:
        TensorFlow Backend:
            >>> keras_core.ops.convert_to_numpy(tf.constant([1, 2, 3]))
            >>> array([1, 2, 3], dtype=int32)

        PyTorch Backend:
            >>> keras_core.ops.convert_to_numpy(torch.Tensor([1, 2, 3]))
            >>> array([1, 2, 3])

    """

    if any_symbolic_tensors((x,)):
        # This will raise a `ValueError` defined in the `KerasTensor` class. We
        # trigger it rather than duplicate it here.
        return np.array(x)
    return backend.convert_to_numpy(x)
